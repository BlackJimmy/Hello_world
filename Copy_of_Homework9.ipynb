{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlackJimmy/Hello_world/blob/main/Copy_of_Homework9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f15dfef",
      "metadata": {
        "id": "1f15dfef"
      },
      "source": [
        "# Question 1\n",
        "\n",
        "Let\n",
        "$$\n",
        "M = \\begin{bmatrix}\n",
        "2 & 1 & -1\\\\\n",
        "0 & -1 & -3 \\\\\n",
        "1 &  0 & -2 \\\\\n",
        "4 & 1 & -5\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Find a basis for $\\mathcal{N}(M)$. What is the rank of $M$?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d509e507",
      "metadata": {
        "id": "d509e507"
      },
      "source": [
        "# Example\n",
        "\n",
        "Now, say that\n",
        "\n",
        "$$\n",
        "M = \\begin{bmatrix}\n",
        "1 & 0 & 1 & 1 \\\\\n",
        "1 & 1 & 2 & 3 \\\\\n",
        "0 & 1 & 1 & 2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Note that $M$ is just the transpose of the matrix from the previous example. So, we should expect that it also has rank 2. We will compute a basis of its nullspace by first computing the RREF:\n",
        "\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 1 & 1 \\\\\n",
        "1 & 1 & 2 & 3 \\\\\n",
        "0 & 1 & 1 & 2\n",
        "\\end{bmatrix} \\mapsto\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 1 & 1 \\\\\n",
        "0 & 1 & 1 & 2 \\\\\n",
        "0 & 1 & 1 & 2\n",
        "\\end{bmatrix} \\mapsto\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 1 & 1 \\\\\n",
        "0 & 1 & 1 & 2 \\\\\n",
        "0 & 0 & 0 & 0\n",
        "\\end{bmatrix}\n",
        "\\end{align*}\n",
        "\n",
        "So, say that $Mx=0$ so that $x\\in\\mathcal{N}(M)$. Then $x$ is in the nullspace of the RREF, so:\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 1 & 1 \\\\\n",
        "0 & 1 & 1 & 2 \\\\\n",
        "0 & 0 & 0 & 0\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\\n",
        "x_2 \\\\\n",
        "x_3 \\\\\n",
        "x_4\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "x_1 +x_3+x_4 \\\\\n",
        "x_2 + x_3 + 2x_4 \\\\\n",
        "0\n",
        "\\end{bmatrix}=0.\n",
        "$$\n",
        "\n",
        "In particular, re-arranging the last equations shows that we can express $x$ as:\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\\n",
        "x_2 \\\\\n",
        "x_3 \\\\\n",
        "x_4\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "-1 \\\\\n",
        "-1 \\\\\n",
        "1 \\\\\n",
        "0\n",
        "\\end{bmatrix}x_3 +\n",
        "\\begin{bmatrix}\n",
        "-1 \\\\\n",
        "-2 \\\\\n",
        "0 \\\\\n",
        "1\n",
        "\\end{bmatrix}x_4\n",
        "$$\n",
        "This calculation shows that\n",
        "$$\n",
        "\\mathcal{N}(M)=\\mathrm{span}\\left\\{\n",
        "\\begin{bmatrix}\n",
        "-1 \\\\\n",
        "-1 \\\\\n",
        "1 \\\\\n",
        "0\n",
        "\\end{bmatrix},\n",
        "\\begin{bmatrix}\n",
        "-1 \\\\\n",
        "-2 \\\\\n",
        "0 \\\\\n",
        "1\n",
        "\\end{bmatrix}\n",
        "\\right\\}\n",
        "$$\n",
        "\n",
        "Furthermore, we can see that this set of vectors is linearly independent, since if\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "-1 \\\\\n",
        "-1 \\\\\n",
        "1 \\\\\n",
        "0\n",
        "\\end{bmatrix}a_1 + \\begin{bmatrix}\n",
        "-1 \\\\\n",
        "-2 \\\\\n",
        "0 \\\\\n",
        "1\n",
        "\\end{bmatrix}\n",
        "a_2 =\n",
        "\\begin{bmatrix}\n",
        "-a_1 -a_2 \\\\\n",
        "-a_1-2a_2 \\\\\n",
        "a_1 \\\\\n",
        "a_2\n",
        "\\end{bmatrix} = 0\n",
        "$$\n",
        "we must have $a_1=a_2=0$.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vnyxG8CaEljw"
      },
      "id": "vnyxG8CaEljw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DHzx0wzdElrT"
      },
      "id": "DHzx0wzdElrT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3yvyOcfVEmvU"
      },
      "id": "3yvyOcfVEmvU"
    },
    {
      "cell_type": "markdown",
      "id": "d95094dd",
      "metadata": {
        "id": "d95094dd"
      },
      "source": [
        "# Question 2\n",
        "\n",
        "Find a basis for $\\mathcal{R}(M)$, for $M$ from the previous problem."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e78b0ccb",
      "metadata": {
        "id": "e78b0ccb"
      },
      "source": [
        "# Linear Algebra Review\n",
        "\n",
        "## Basic Facts and Definitions\n",
        "\n",
        "Let $M$ be an $m\\times n$ matrix. We will be talking about matrices with real entries, but all of the discussion applies with minimal modification to matrices with complex entries.\n",
        "\n",
        "The *null space* of $M$, $\\mathcal{N}(M)$ is the set of vectors, $x\\in\\mathbb{R}^n$ such that $Mx=0$. This set is expressed in mathematical notation as:\n",
        "$$\n",
        "\\mathcal{N}(M)=\\{x\\in\\mathbb{R}^n|Mx=0\\}.\n",
        "$$\n",
        "\n",
        "So, $\\mathcal{N}(M)$ is the set of vectors that $M$ maps to zero.\n",
        "\n",
        "**Fact:** If $A$ is an invertible matrix $m\\times m$, then $\\mathcal{N}(AM)=\\mathcal{N}(M)$.\n",
        "\n",
        "In other words, multiplying $M$ on the left by an invertible matrix does not change its null space.\n",
        "\n",
        "The *range space* of $M$, $\\mathcal{R}(M)$ is the set of vectors $y$ such that $y=Mx$  for some $x$. This set is expressed in mathematical notation as:\n",
        "$$\n",
        "\\mathcal{R}(M)=\\{y\\in\\mathbb{R}^m|y=Mx\\textrm{ for some } x \\in\\mathbb{R}^n\\}\n",
        "$$\n",
        "\n",
        "So, $\\mathcal{R}(M)$ is the set of vectors that could be reached by an appropriate choice of $x$.\n",
        "\n",
        "**Fact:** If $B$ is an inverble $n\\times n$ matrix, then $\\mathcal{R}(MB)=\\mathcal{R}(M)$.\n",
        "\n",
        "In other words, multiplying $M$ on the right by an invertible matrix does not change its range space.\n",
        "\n",
        "\n",
        "A set of vectors  $\\{v_1,v_2,\\ldots,v_k\\}$ is called linearly independent if the only set of scalar coefficients $a_1,a_2,\\ldots,a_k$ such that\n",
        "$$\n",
        "a_1 v_1 + a_2 v_2 + \\cdots + a_k v_k = 0\n",
        "$$\n",
        "is $a_1=a_2=\\cdots=a_k=0$.\n",
        "\n",
        "If we stack vectors into a matrix, $V=\\begin{bmatrix}v_1 & v_2 &\\cdots & v_k\\end{bmatrix}$, we see  that the vectors are linearly independent if and only if $0$ is the only vector in the null space of $V$. In other words, $\\{v_1,v_2,\\ldots,v_k\\}$ are linearly independent if and only if $\\mathcal{N}(V)=\\{0\\}$.  \n",
        "\n",
        "A set of vectors, $\\{v_1,v_2,\\ldots,v_k\\}$, is called *linearly dependent* if it is not linearly independent. In terms fo the matrix $V$, this means that there is a vector $a\\ne 0$ with $a\\in\\mathcal{N}(V)$.\n",
        "\n",
        "**Fact:** $\\mathcal{N}(V)=\\{0\\}$ if and only if $V^\\top V$ is invertible.\n",
        "\n",
        "The *span* of the vectors $\\{v_1,v_2,\\ldots,v_k\\}$ is the set of $y$ such that there are scalar coefficients, $a_1,\\ldots,a_k$ such that\n",
        "$$\n",
        "y=a_1 v_1 + a_2 v_2 + \\cdots + a_k v_k\n",
        "$$\n",
        "\n",
        "In particular,\n",
        "$$\n",
        "\\mathrm{span}\\left(\\{v_1,v_2,\\ldots,v_k\\}\\right) = \\mathcal{R}(V),\n",
        "$$\n",
        "where $V=\\begin{bmatrix}v_1 & v_2 &\\cdots & v_k\\end{bmatrix}$.\n",
        "\n",
        "A set of vectors, $\\mathcal{X}$ is called a vector space if for all $x,y\\in\\mathcal{X}$ and all scalars $a$ and $b$, we have that\n",
        "$$\n",
        "ax+by\\in\\mathcal{X}.\n",
        "$$\n",
        "\n",
        "**Fact:** The range space and null space of a matrix are vector spaces.\n",
        "\n",
        "A set of vectors $\\{v_1,\\ldots,v_k\\}$ is called a *basis* of the vector space $\\mathcal{X}$ if\n",
        "* $\\mathcal{X}=\\mathrm{span}\\left(\\{v_1,\\ldots,v_k\\} \\right)$\n",
        "* The set $\\{v_1,\\ldots,v_k\\}$ is linearly independent.\n",
        "\n",
        "These conditions can be expressed in terms of the matrix $V$ as\n",
        "* $\\mathcal{X}=\\mathcal{R}(V)$\n",
        "* $\\mathcal{N}(V)=\\{0\\}$\n",
        "\n",
        "**Fact:** All bases of a vector space $\\mathcal{X}$ have the same size.\n",
        "\n",
        "The *dimension* of $\\mathcal{X}$, denoted by $\\mathrm{dim}(\\mathcal{X})$ is the number of vectors in a basis of $\\mathcal{X}$.\n",
        "\n",
        "A basis of $\\mathcal{X}$ gives a minimal description of all of the vectors in the set $\\mathcal{X}$.\n",
        "\n",
        "\n",
        "The *rank* of a matrix, $M$, is the dimension of its range space, i.e. $\\mathrm{rank}(M)=\\mathrm{dim}(\\mathcal{R}(M))$.\n",
        "\n",
        "**Facts:**\n",
        "* $\\mathrm{rank}(M)$ is also the size of the largest linearly independent set of columns of $M$\n",
        "* $\\mathrm{rank}(M)$ is also the size of the largest linearly independent set of rows of $M$\n",
        "\n",
        "**Fact:**\n",
        "If $M$ is an $m\\times n$ matrix, then\n",
        "$$\n",
        "n = \\mathrm{rank}(M)+\\mathrm{dim}(\\mathcal{N}(M)).\n",
        "$$\n",
        "This result is known as the *rank-nullity* theorem, as the dimension of the null space is sometimes callled the nullity.\n",
        "\n",
        "## Example\n",
        "\n",
        "We will give an example of how to compute bases of the null space and the range space. We will go through the steps in a fair amount of detail.\n",
        "\n",
        "Let\n",
        "\n",
        "$$\n",
        "M = \\begin{bmatrix}\n",
        "1 & 1 & 0 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "1 & 2 &  1 \\\\\n",
        "1 & 3 & 2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "We can write $M=\\begin{bmatrix}m_1^\\top \\\\ m_2^\\top \\\\ m_3^\\top \\\\ m_4^\\top \\end{bmatrix}$, where each $m_i$ is a row of $M$. Note that if $x\\in \\mathcal{N}(M)$, then we must ahve that $m_i^\\top x=0$ for each row of $M$.\n",
        "\n",
        "This implies that null-space does not change if we do one of the *elementary row operations* from Gaussian elimination:\n",
        "* Muliplying a row by a non-zero constant: $m_i^\\top \\mapsto cm_i^\\top$\n",
        "* Adding a constant multiple of one row to another: $m_i^\\top \\mapsto m_i^\\top + cm_j^\\top$\n",
        "* Swapping rows: $m_i^\\top \\mapsto m_j^\\top$ and $m_j^\\top \\mapsto m_i^\\top$\n",
        "\n",
        "All elementary row operations can be implemented by multiplying $M$ on the left by an appropriate invertible matrix. This implies that the null space of $M$ must be the same as the null space of the reduced row eschelon form.\n",
        "\n",
        "So, we will now compute the null space of $M$ by first computing the reduced row eschelon form (RREF), and then finding a basis of the null space of the corresponding matrix.\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix}\n",
        "1 & 1 & 0 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "1 & 2 &  1 \\\\\n",
        "1 & 3 & 2\n",
        "\\end{bmatrix} \\mapsto\n",
        "\\begin{bmatrix}\n",
        "1 & 1 & 0 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "0 & 1 &  1 \\\\\n",
        "0 & 2 & 2\n",
        "\\end{bmatrix} \\mapsto\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & -1 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "0 & 0 &  0 \\\\\n",
        "0 & 0 & 0\n",
        "\\end{bmatrix}\n",
        "\\end{align*}\n",
        "\n",
        "So, we can see if $x=\\begin{bmatrix}x_1 \\\\x_2 \\\\x_3 \\end{bmatrix}$ and $Mx=0$, then we must have $x_1-x_3=0$  and $x_2+x_3$. Specifically, $x$ must have the form\n",
        "$$\n",
        "x=\\begin{bmatrix}\n",
        "1 \\\\\n",
        "-1 \\\\\n",
        "1\n",
        "\\end{bmatrix}a\n",
        "$$\n",
        "for some number $a$. So, we have just shown that $\\mathcal{N}(M) \\subset \\mathrm{span}\\left( \\begin{bmatrix}\n",
        "1 \\\\\n",
        "-1 \\\\\n",
        "1\n",
        "\\end{bmatrix}\\right)$.\n",
        "\n",
        "Conversely, direct calculation shows that\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 1 & 0 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "1 & 2 &  1 \\\\\n",
        "1 & 3 & 2\n",
        "\\end{bmatrix}\\begin{bmatrix}\n",
        "1 \\\\\n",
        "-1 \\\\\n",
        "1\n",
        "\\end{bmatrix}a=0\n",
        "$$\n",
        "So, we $\\mathrm{span}\\left( \\begin{bmatrix}\n",
        "1 \\\\\n",
        "-1 \\\\\n",
        "1\n",
        "\\end{bmatrix}\\right)\\subset \\mathcal{N}(M)$, and so the two sets must be equal.\n",
        "\n",
        "Note that $\\mathcal{N}(M)=\\mathcal{R}(v)$, with $v=\\begin{bmatrix}\n",
        "1 \\\\\n",
        "-1 \\\\\n",
        "1\n",
        "\\end{bmatrix}$. Note that $\\mathcal{N}(v)=\\{0\\}$ since $v^\\top v = 3 >0$, which corresponds to an invertible matrix.\n",
        "\n",
        "Finding a basis of the range space is potentially easier. Namely, any maximal collection of linearly independent columns forms a basis of the null space. A simple scheme for doing this is just adding vectors to the basis, one at a time, and checking if the resulting set is linearly indepent:\n",
        "\n",
        "We start with the first column $\\{v_1\\}$, where $v_1=\\begin{bmatrix}1\\\\0\\\\1\\\\1\\end{bmatrix}$. Based on what we saw above, as long as $v_1\\ne 0$, we must have that $\\{v_1\\}$ is linearly independent. So, check if the set remains linearly independent if we add the column $v_2 = \\begin{bmatrix}1 \\\\ 1 \\\\ 2\\\\ 3\\end{bmatrix}$. We can check this either by the invertibility test, or by directly checking the null space of  the resulting matrix. We'll check the null-space:\n",
        "\n",
        "\\begin{align*}\n",
        "\\underbrace{\\begin{bmatrix}\n",
        "1 & 1  \\\\\n",
        "0 & 1  \\\\\n",
        "1 & 2 \\\\\n",
        "1 & 3\n",
        "\\end{bmatrix}}_V\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\\n",
        "x_2\n",
        "\\end{bmatrix} &=\n",
        "\\begin{bmatrix}\n",
        "x_1 + x_2 \\\\\n",
        "x_2 \\\\\n",
        "x_1 + 2x_2 \\\\\n",
        "x_1+3x_2\n",
        "\\end{bmatrix}=0\n",
        "\\end{align*}\n",
        "So, to make this equation hold, the second row implies that we must have that $x_2=0$. Thus, the remaining rows imply that $x_1=0$. Thus, this set is linearly independent.\n",
        "\n",
        "Now, the rank nullity theorem implies that $\\mathrm{rank}(M)=2=3-\\mathrm{dim}(\\mathcal{N}(M))$, so the columns of $V$ must be a basis of the range space.\n",
        "\n",
        "Furthermore, we saw above that $\\begin{bmatrix}\n",
        "1 \\\\\n",
        "-1 \\\\\n",
        "1\n",
        "\\end{bmatrix}$ is in the null space of $M$, so if we included the third column in our set of vectors, it would fail to be linearly independent.\n",
        "\n",
        "A possibly more systematic approach to finding a basis of the range space is by computing the reduced column eschelon form. Here, we do the same operationns as in standard Gaussian elimination, except we operate on columns. (One could do this by first transposing the mattrix, computing the RREF, and then transposing back.)\n",
        "\n",
        "Just as in the discussion of elementary row operations, each elementary column operation corresponds to multiplying the matrix on the right by an invertible matrix. So, by the facts above, $M$ and its reduced column eschelon form have the same range space. Let's see how this works:\n",
        "\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix}\n",
        "1 & 1 & 0 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "1 & 2 &  1 \\\\\n",
        "1 & 3 & 2\n",
        "\\end{bmatrix}\\mapsto\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "1 & 1 &  1 \\\\\n",
        "1 & 2 & 2\n",
        "\\end{bmatrix} \\mapsto\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "0 & 1 & 0 \\\\\n",
        "1 & 1 &  0 \\\\\n",
        "1 & 2 & 0\n",
        "\\end{bmatrix}\n",
        "\\end{align*}\n",
        "The first two columns of this matrix also form a basis of the range space.# Linear Algebra Review\n",
        "\n",
        "## Basic Facts and Definitions\n",
        "\n",
        "Let $M$ be a matrix.\n",
        "\n",
        "The *null space* of $M$, $\\mathcal{N}(M)$ is the set of vectors, $x$ such that $Mx=0$. This set is expressed in mathematical notation as:\n",
        "$$\n",
        "\\mathcal{N}(M)=\\{x|Mx=0\\}.\n",
        "$$\n",
        "\n",
        "So, $\\mathcal{N}(M)$ is the set of vectors that $M$ maps to zero.\n",
        "\n",
        "**Fact:** If $A$ is an invertible matrix, then $\\mathcal{N}(AM)=\\mathcal{N}(M)$, as long as the multiplication, $AM$ is well-defined.\n",
        "\n",
        "In other words, multiplying $M$ on the left by an invertible matrix does not change its null space.\n",
        "\n",
        "The *range space* of $M$, $\\mathcal{R}(M)$ is the set of vectors $y$ such that $y=Mx$  for some $x$. This set is expressed in mathematical notation as:\n",
        "$$\n",
        "\\mathcal{R}(M)=\\{y|y=Mx\\textrm{ for some } x\\}\n",
        "$$\n",
        "\n",
        "So, $\\mathcal{R}(M)$ is the set of vectors that could be reached by an appropriate choice of $x$.\n",
        "\n",
        "**Fact:** If $B$ is an inverble matrix, then $\\mathcal{R}(MB)=\\mathcal{R}(M)$, as long as the multiplication,$MB$, is well-defined.\n",
        "\n",
        "In other wrods, multiplying $M$ on the right by an invertible matrix does not change its range space.\n",
        "\n",
        "\n",
        "A set of vectors  $\\{v_1,v_2,\\ldots,v_k\\}$ is called linearly independent if the only set of scalar coeeficients $a_1,a_2,\\ldots,a_k$ such that\n",
        "$$\n",
        "a_1 v_1 + a_2 v_2 + \\cdots + a_k v_k = 0\n",
        "$$\n",
        "is $a_1=a_2=\\cdots=a_k=0$.\n",
        "\n",
        "If we stack vectors into a matrix, $V=\\begin{bmatrix}v_1 & v_2 &\\cdots & v_k\\end{bmatrix}$, we see  that the vectors are linearly independent if and only if $0$ is the only vector in the null space of $V$. In other words, $\\{v_1,v_2,\\ldots,v_k\\}$ are linearly independent if and only if $\\mathcal{N}(V)=\\{0\\}$.  \n",
        "\n",
        "A set of vectors, $\\{v_1,v_2,\\ldots,v_k\\}$, is called *linearly dependent* if it is not linearly independent. In terms fo the matrix $V$, this means that there is a vector $a\\ne 0$ with $a\\in\\mathcal{N}(V)$.\n",
        "\n",
        "**Fact:** $\\mathcal{N}(V)=\\{0\\}$ if and only if $V^\\top V$ is invertible.\n",
        "\n",
        "The *span* of the vectors $\\{v_1,v_2,\\ldots,v_k\\}$ is the set of $y$ such that there are scalar coefficients, $a_1,ldots,a_k$ such that\n",
        "$$\n",
        "y=a_1 v_1 + a_2 v_2 + \\cdots + a_k v_k\n",
        "$$\n",
        "\n",
        "In particular,\n",
        "$$\n",
        "\\mathrm{span}\\left(\\{v_1,v_2,\\ldots,v_k\\}\\right) = \\mathcal{R}(V),\n",
        "$$\n",
        "where $V=\\begin{bmatrix}v_1 & v_2 &\\cdots & v_k\\end{bmatrix}$.\n",
        "\n",
        "A set of vectors, $\\mathcal{X}$ is called a vector space if for all $x,y\\in\\mathcal{X}$ and all scalars $a$ and $b$, we have that\n",
        "$$\n",
        "ax+by\\in\\mathcal{X}.\n",
        "$$\n",
        "\n",
        "**Fact:** The range space and null space of a matrix are vector spaces.\n",
        "\n",
        "A set of vectors $\\{v_1,\\ldots,v_k\\}$ is called a *basis* of the vector space $\\mathcal{X}$ if\n",
        "* $\\mathcal{X}=\\mathrm{span}\\left(\\{v_1,\\ldots,v_k\\} \\right)$\n",
        "* The set $\\{v_1,\\ldots,v_k\\}$ is linearly independent.\n",
        "\n",
        "These conditions can be expressed in terms of the matrix $V$ as\n",
        "* $\\mathcal{X}=\\mathcal{R}(V)$\n",
        "* $\\mathcal{N}(V)=\\{0\\}$\n",
        "\n",
        "**Fact:** All bases of a vector space $\\mathcal{X}$ have the same size.\n",
        "\n",
        "The *dimension* of $\\mathcal{X}$, denoted by $\\mathrm{dim}(\\mathcal{X})$ is the number of vectors in a basis of $\\mathcal{X}$.\n",
        "\n",
        "A basis of $\\mathcal{X}$ gives a minimal description of all of the vectors in the set $\\mathcal{X}$.\n",
        "\n",
        "\n",
        "The *rank* of a matrix, $M$, is the dimension of its range space, i.e. $\\mathrm{rank}(M)=\\mathrm{dim}(\\mathcal{R}(M))$.\n",
        "\n",
        "**Facts:**\n",
        "* $\\mathrm{rank}(M)$ is also the size of the largest linearly independent set of columns of $M$\n",
        "* $\\mathrm{rank}(M)$ is also the size of the largest linearly independent set of rows of $M$\n",
        "\n",
        "**Fact:**\n",
        "If $M$ is an $m\\times n$ matrix, then\n",
        "$$\n",
        "n = \\mathrm{rank}(M)+\\mathrm{dim}(\\mathcal{N}(M)).\n",
        "$$\n",
        "This result is known as the *rank-nullity* theorem, as the dimension of the null space is sometimes callled the nullity.\n",
        "\n",
        "## Example\n",
        "\n",
        "We will give an example of how to compute bases of the null space and the range space. We will go through the steps in a fair amount of detail.\n",
        "\n",
        "Let\n",
        "\n",
        "$$\n",
        "M = \\begin{bmatrix}\n",
        "1 & 1 & 0 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "1 & 2 &  1 \\\\\n",
        "1 & 3 & 2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "We can write $M=\\begin{bmatrix}m_1 \\\\ m_2 \\\\ m_3 \\\\ m_4 \\end{bmatrix}$, where each $m_i$ is a row of $M$. Note that if $x\\in \\mathcal{N}(M)$, then we must have that $m_i x=0$ for each row of $M$.\n",
        "\n",
        "This implies that null-space does not change if we do one of the *elementary row operations* from Gaussian elimination:\n",
        "* Muliplying a row by a non-zero constant: $m_i \\mapsto cm_i$\n",
        "* Adding a constant multiple of one row to another: $m_i \\mapsto m_i + cm_j$\n",
        "* Swapping rows: $m_i \\mapsto m_j$ and $m_j \\mapsto m_i$\n",
        "\n",
        "All elementary row operations can be implemented by multiplying $M$ on the left by an appropriate invertible matrix. This implies that the null space of $M$ must be the same as the null space of the reduced row eschelon form.\n",
        "\n",
        "So, we will now compute the null space of $M$ by first computing the reduced row eschelon form (RREF), and then finding a basis of the null space of the corresponding matrix.\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix}\n",
        "1 & 1 & 0 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "1 & 2 &  1 \\\\\n",
        "1 & 3 & 2\n",
        "\\end{bmatrix} \\mapsto\n",
        "\\begin{bmatrix}\n",
        "1 & 1 & 0 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "0 & 1 &  1 \\\\\n",
        "0 & 2 & 2\n",
        "\\end{bmatrix} \\mapsto\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & -1 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "0 & 0 &  0 \\\\\n",
        "0 & 0 & 0\n",
        "\\end{bmatrix}\n",
        "\\end{align*}\n",
        "\n",
        "So, we can see if $x=\\begin{bmatrix}x_1 \\\\x_2 \\\\x_3 \\end{bmatrix}$ and $Mx=0$, then we must have $x_1-x_3=0$  and $x_2+x_3=0$. Specifically, $x$ must have the form\n",
        "$$\n",
        "x=\\begin{bmatrix}\n",
        "1 \\\\\n",
        "-1 \\\\\n",
        "1\n",
        "\\end{bmatrix}a\n",
        "$$\n",
        "for some number $a$. So, we have just shown that $\\mathcal{N}(M) \\subset \\mathrm{span}\\left( \\begin{bmatrix}\n",
        "1 \\\\\n",
        "-1 \\\\\n",
        "1\n",
        "\\end{bmatrix}\\right)$.\n",
        "\n",
        "Conversely, direct calculation shows that\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 1 & 0 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "1 & 2 &  1 \\\\\n",
        "1 & 3 & 2\n",
        "\\end{bmatrix}\\begin{bmatrix}\n",
        "1 \\\\\n",
        "-1 \\\\\n",
        "1\n",
        "\\end{bmatrix}a=0\n",
        "$$\n",
        "So, we $\\mathrm{span}\\left( \\begin{bmatrix}\n",
        "1 \\\\\n",
        "-1 \\\\\n",
        "1\n",
        "\\end{bmatrix}\\right)\\subset \\mathcal{N}(M)$, and so the two sets must be equal.\n",
        "\n",
        "Note that $\\mathcal{N}(M)=\\mathcal{R}(v)$, with $v=\\begin{bmatrix}\n",
        "1 \\\\\n",
        "-1 \\\\\n",
        "1\n",
        "\\end{bmatrix}$. Note that $\\mathcal{N}(v)=\\{0\\}$ since $v^\\top v = 3 >0$, which corresponds to an invertible matrix.\n",
        "\n",
        "Finding a basis of the range space is potentially easier. Namely, any maximal collection of linearly independent columns forms a basis of the null space. A simple scheme for doing this is just adding vectors to the basis, one at a time, and checking if the resulting set is linearly indepent:\n",
        "\n",
        "We start with the first column $\\{v_1\\}$, where $v_1=\\begin{bmatrix}1\\\\0\\\\1\\\\1\\end{bmatrix}$. Based on what we saw above, as long as $v_1\\ne 0$, we must have that $\\{v_1\\}$ is linearly independent. So, check if the set remains linearly independent if we add the column $v_2 = \\begin{bmatrix}1 \\\\ 1 \\\\ 2\\\\ 3\\end{bmatrix}$. We can check this either by the invertibility test, or by directly checking the null space of  the resulting matrix. We'll check the null-space:\n",
        "\n",
        "\\begin{align*}\n",
        "\\underbrace{\\begin{bmatrix}\n",
        "1 & 1  \\\\\n",
        "0 & 1  \\\\\n",
        "1 & 2 \\\\\n",
        "1 & 3\n",
        "\\end{bmatrix}}_V\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\\n",
        "x_2\n",
        "\\end{bmatrix} &=\n",
        "\\begin{bmatrix}\n",
        "x_1 + x_2 \\\\\n",
        "x_2 \\\\\n",
        "x_1 + 2x_2 \\\\\n",
        "x_1+3x_2\n",
        "\\end{bmatrix}=0\n",
        "\\end{align*}\n",
        "So, to make this equation hold, the second row implies that we must have that $x_2=0$. Thus, the remaining rows imply that $x_1=0$. Thus, this set is linearly independent.\n",
        "\n",
        "Now, the rank nullity theorem implies that $\\mathrm{rank}(M)=2=3-\\mathrm{dim}(\\mathcal{N}(M))$, so the columns of $V$ must be a basis of the range space.\n",
        "\n",
        "Furthermore, we saw above that $\\begin{bmatrix}\n",
        "1 \\\\\n",
        "-1 \\\\\n",
        "1\n",
        "\\end{bmatrix}$ is in the null space of $M$, so if we included the third column in our set of vectors, it would fail to be linearly independent.\n",
        "\n",
        "A possibly more systematic approach to finding a basis of the range space is by computing the reduced column eschelon form. Here, we do the same operationns as in standard Gaussian elimination, except we operate on columns. (One could do this by first transposing the matrix, computing the RREF, and then transposing back.)\n",
        "\n",
        "Just as in the discussion of elementary row operations, each elementary column operation corresponds to multiplying the matrix on the right by an invertible matrix. So, by the facts above, $M$ and its reduced column eschelon form have the same range space. Let's see how this works:\n",
        "\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix}\n",
        "1 & 1 & 0 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "1 & 2 &  1 \\\\\n",
        "1 & 3 & 2\n",
        "\\end{bmatrix}\\mapsto\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "1 & 1 &  1 \\\\\n",
        "1 & 2 & 2\n",
        "\\end{bmatrix} \\mapsto\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "0 & 1 & 0 \\\\\n",
        "1 & 1 &  0 \\\\\n",
        "1 & 2 & 0\n",
        "\\end{bmatrix}\n",
        "\\end{align*}\n",
        "The first two columns of this matrix also form a basis of the range space."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gmMAwG1D-hDs"
      },
      "id": "gmMAwG1D-hDs"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O4XPXSPi-iQ-"
      },
      "id": "O4XPXSPi-iQ-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Singular Value Decomposition.\n",
        "\n",
        "If $M$ is an $m\\times n$ matrix with rank $r$, then there are matrices $U_1 \\in\\mathbb{R}^{m\\times r}$, $U_2 \\in\\mathbb{R}^{m\\times (m-r)}$, $\\Sigma\\in \\mathbb{R}^{r\\times r}$, $V_1 \\in \\mathbb{R}^{n\\times r}$, and $V_2\\in \\mathbb{R}^{n\\times (n-r)}$ such that:\n",
        "* \\begin{equation*}\n",
        "M = \\begin{bmatrix}\n",
        "U_1 & U_2\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "\\Sigma & 0_{r\\times (n-r)} \\\\\n",
        "0_{(m-r)\\times r} & 0_{(m-r)\\times (n-r)}\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "V_1^\\top \\\\\n",
        "V_2^\\top\n",
        "\\end{bmatrix}\n",
        "\\end{equation*}\n",
        "* $\\Sigma = \\begin{bmatrix}\\sigma_1 & &  \\\\\n",
        "& \\ddots & \\\\\n",
        "&& \\sigma_r\\end{bmatrix}$ is a diagonal matrix and $\\sigma_1\\ge \\sigma_2 \\ge \\cdots\\ge \\sigma_r >0$ are called the \\emph{singular values} of $M$.\n",
        "* The columns of $U_1$ form a basis of $\\mathcal{R}(M)$\n",
        "* The columns of $V_2$ form a basis of $\\mathcal{N}(M)$\n",
        "* The matrix $U=\\begin{bmatrix}U_1 & U_2\\end{bmatrix}$ is orthogonal. i.e. $U^\\top U=UU^\\top = I$.\n",
        "* The matrix $V=\\begin{bmatrix}V_1 & V_2\\end{bmatrix}$ is orthogonal. i.e. $V^\\top V=VV^\\top = I$.\n",
        "\n",
        "Computers are good at computing singular  value decompositions (SVDs), even if they are tedious to do by hand. The `Scipy` command for the singular value is `la.svd`.\n",
        "\n",
        "However, one issue with computing the SVD is that floating point errors show up, and it is impossible to distinguish between very small singular values and $0$. (This is related to the numerical instability of rank, discussed in class.)\n",
        "\n",
        "So, instead of computing $\\sigma_1,\\ldots,\\sigma_r$, the numerical methods will output $\\sigma_1,\\sigma_2,\\ldots,\\sigma_r,\\sigma_{r+1},\\ldots,\\sigma_{\\min\\{m,n\\}}$, where $\\sigma_{r+1},\\ldots,\\sigma_{\\min\\{m,n\\}}$ will be tiny numbers arising from floating point errors.\n",
        "\n",
        "Likewise, the numerical methods will return $U$ and $V$ (or `scipy` returns $U$ and $V^\\top$), rather than the partitioned matrices described above.\n",
        "\n",
        "Then, since the computer does not try to actually calculate $r$, if you wanted to know $U_1$, $U_2$, $V_1$, and $V_2$, you'd need to decide what $r$ should be, and then partition the $U$ and $V$.\n",
        "\n",
        "The typical method to calculate $r$ is to pick some error tolerance, $\\epsilon$, such as $10^{-12}$ and declare that $\\sigma_i=0$ if you calculated that $\\sigma_i < \\epsilon$.\n",
        "\n",
        "# Question 3\n",
        "\n",
        "Compute the singular value decomposition of $M$ from the previous problem. In particular, look at the singular values of $M$ to determine what $r$ is. Then calculate $U_1$ and $V_2$ and print the results.\n",
        "\n",
        "Check in particular that $MV_2 = 0$\n"
      ],
      "metadata": {
        "id": "cpwXafzozREJ"
      },
      "id": "cpwXafzozREJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Put your code here\n",
        "\n",
        "import numpy as np\n",
        "import scipy.linalg as la\n",
        "M = np.array([[2,1,-1.],\n",
        "              [0,-1,-3],\n",
        "              [1,0,-2],\n",
        "              [4,1,-5]])"
      ],
      "metadata": {
        "id": "_hR6lQuD1js8"
      },
      "id": "_hR6lQuD1js8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "U,S,Vt = la.svd(M)\n",
        "\n",
        "print('Singular Values')\n",
        "print(S)\n",
        "U1 = U[:,:2]\n",
        "V2 = Vt[2:].T\n",
        "print('U1')\n",
        "print(U1)\n",
        "print('V2')\n",
        "print(V2)\n",
        "print('MV_2')\n",
        "print(M@V2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3ZaNxZb1WBH",
        "outputId": "5a676318-74a2-45a4-9d9a-372de48e7577"
      },
      "id": "P3ZaNxZb1WBH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Singular Values\n",
            "[7.50227082e+00 2.59151163e+00 2.37484731e-16]\n",
            "U1\n",
            "[[-0.27546785  0.50739609]\n",
            " [-0.31042269 -0.82547897]\n",
            " [-0.29294527 -0.15904144]\n",
            " [-0.86135839  0.18931322]]\n",
            "V2\n",
            "[[ 0.53452248]\n",
            " [-0.80178373]\n",
            " [ 0.26726124]]\n",
            "MV_2\n",
            "[[3.33066907e-16]\n",
            " [3.33066907e-16]\n",
            " [3.33066907e-16]\n",
            " [9.99200722e-16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "151f4fad",
      "metadata": {
        "id": "151f4fad"
      },
      "source": [
        "# Question 4\n",
        "\n",
        "Now say\n",
        "$$\n",
        "M = \\begin{bmatrix}\n",
        "2 & 0 & 1 & 4 \\\\\n",
        "1 & -1 & 0 & 1 \\\\\n",
        "-1 & -3 & -2 & -5\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Find a basis for $\\mathcal{N}(M)$. What is $\\mathrm{rank}(M)$? You should probably do this by hand, but know that we could always just  use the SVD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aefc022",
      "metadata": {
        "id": "0aefc022"
      },
      "source": [
        "# Question 5\n",
        "\n",
        "Consider the discrete-time system:\n",
        "$$\n",
        "x[k+1] = \\underbrace{\\begin{bmatrix}\n",
        "\\frac{1}{2}  & 1 & 0\\\\\n",
        "0 & \\frac{1}{2} & 1  \\\\\n",
        "0 & 0 & \\frac{1}{2}\n",
        "\\end{bmatrix}}_{A}x[k]+\\underbrace{\\begin{bmatrix}\n",
        "0 \\\\\n",
        "1 \\\\\n",
        "0\n",
        "\\end{bmatrix}}_{B}u[k]\n",
        "$$\n",
        "\n",
        "Calculate the controllability matrix of this system. In this case, the controllability matrix is:\n",
        "$$\n",
        "\\mathcal{C}=\\begin{bmatrix}\n",
        "B &  AB & A^2 B\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "506c87e0",
      "metadata": {
        "id": "506c87e0"
      },
      "source": [
        "# Reachable Sets\n",
        "\n",
        "Say that\n",
        "$$\n",
        "x[k+1] = Ax[k]+Bu[k]\n",
        "$$\n",
        "with $x[0]=0$.\n",
        "\n",
        "We say that at vector $z$ is reachable if there is a time $\\tau$ and sequence of inputs $u[0],\\ldots,u[\\tau-1]$ such that leads to $x[\\tau]=z$. (In other words, $z$ is reachable if there is an input that drives the system state to $z$ in a finite number of steps.)\n",
        "\n",
        "If $\\mathcal{C}$ is the controllability matrix, then the reachable set is precisely its range space, $\\mathcal{R}(\\mathcal{C})$. (The same exact statement is true in continuous-time as well.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "181e8da4",
      "metadata": {
        "id": "181e8da4"
      },
      "source": [
        "# Question 6\n",
        "\n",
        "Calculate a basis of the reachable set for the system from the previous problem. Feel free to do this by hand, or with the computer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c08b1761",
      "metadata": {
        "id": "c08b1761"
      },
      "source": [
        "# Question 7\n",
        "\n",
        "Consider the discrete-time system:\n",
        "$$\n",
        "x[k+1] = \\underbrace{\\begin{bmatrix}\n",
        "\\frac{1}{2}  & 1 & 0\\\\\n",
        "0 & \\frac{1}{2} & 1  \\\\\n",
        "0 & 0 & \\frac{1}{2}\n",
        "\\end{bmatrix}}_{A}x[k]+\\underbrace{\\begin{bmatrix}\n",
        "0 & 0 \\\\\n",
        "1 & 0 \\\\\n",
        "0 & 1\n",
        "\\end{bmatrix}}_{B}u[k]\n",
        "$$\n",
        "\n",
        "Calculate the controllability matrix of this system"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2da3ce0",
      "metadata": {
        "id": "b2da3ce0"
      },
      "source": [
        "# Left and right pseudo-inverses\n",
        "\n",
        "Let $M$ be an $m\\times n$ matrix. If $M$ is not square, then it cannot be invertible. However, if $M$ has full rank (which will be $m$ if $m\\le n$ and $n$ if $n\\le m$), then $M$ has either a left or right pseudo-inverse. Namely, we have the following facts:\n",
        "* If $\\mathrm{rank}(M)=m$, then $MM^\\top$ is invertible, so $M\\left(M^\\top (MM^\\top)^{-1}\\right)=I$.  Here $M^\\top (MM^\\top)^{-1}$ is called the *right pseudo-inverse* since multiplying on the right gives the identity.\n",
        "* If $\\mathrm{rank}(M)=n$, then $M^\\top M$ is invertible, so $\\left((M^\\top M)^{-1}M^\\top\\right) M =I$. Here $(M^\\top M)^{-1}M^\\top$ is called the *left pseudo-inverse* since multiplying on the left gives the identity.    \n",
        "\n",
        "When a right pseudo-inverse exists, it can be used to find a solution $x$ to the equation $y=Mx$, for any $y$. (When $m<n$, many solutions can exist, and the calculation below gives one of them.)\n",
        "\n",
        "Namely, we set $x=M^\\top (MM^\\top)^{-1}y$ and plug in to give:\n",
        "$$\n",
        "Mx=MM^\\top (MM^\\top)^{-1}y = y.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 8\n",
        "\n",
        "Now say that $M$ is an $m\\times n$ matrix with $\\mathrm{rank}(M)=m< n$. In this case, the singular value decomposition takes the form:\n",
        "$$\n",
        "M=U \\begin{bmatrix}\\Sigma & 0_{m\\times (n-m)}\\end{bmatrix}V^\\top.\n",
        "$$\n",
        "Calculate an expression for the right pseudoinverse in terms of $U$ and $\\Sigma$."
      ],
      "metadata": {
        "id": "-BYlakwD_Pne"
      },
      "id": "-BYlakwD_Pne"
    },
    {
      "cell_type": "markdown",
      "id": "cd4c629c",
      "metadata": {
        "id": "cd4c629c"
      },
      "source": [
        "# Question 9\n",
        "\n",
        "Calculate the right pseudo-inverse of the controllability matrix from the previous question. Feel free to use code for this one."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "103bd2b7",
      "metadata": {
        "id": "103bd2b7"
      },
      "source": [
        "# Question 10\n",
        "\n",
        "Note that if $x[0]=0$, then\n",
        "$$\n",
        "x[3] = \\begin{bmatrix}\n",
        "B & AB & A^2 B\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "u[2]\\\\\n",
        "u[1] \\\\\n",
        "u[0]\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Use your right pseudo-inverse of the controllability matrix to find $u[0],u[1],u[2]$ such that $x[3] = \\begin{bmatrix}\n",
        "1 \\\\\n",
        "2 \\\\\n",
        "3\n",
        "\\end{bmatrix}$.\n",
        "\n",
        "Again, it makes sense to use code for this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc18526c",
      "metadata": {
        "id": "cc18526c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}